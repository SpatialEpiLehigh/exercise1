[
  {
    "objectID": "ex1.html",
    "href": "ex1.html",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "",
    "text": "By the end of this exercise, you will be able to:\n\nGeocode a set of addresses using the Census Bureau geocoder\nCalculate and interpret geocoding match rates\nIdentify and analyse failed geocodes\nCreate interactive maps to visualise spatial and temporal patterns\nUnderstand how geocoding quality affects downstream spatial analysis\nApply geographic masking (geomasking) to protect privacy while preserving spatial patterns\nApply the full geocoding-to-visualisation workflow independently on a new dataset of your choosing\n\n\n\n\nThis exercise uses criminal homicides that occurred in Philadelphia during 2025. The dataset includes incident details and address information, but coordinates have been removed. You must geocode these addresses and analyze the spatial and temporal patterns."
  },
  {
    "objectID": "ex1.html#learning-objectives",
    "href": "ex1.html#learning-objectives",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "",
    "text": "By the end of this exercise, you will be able to:\n\nGeocode a set of addresses using the Census Bureau geocoder\nCalculate and interpret geocoding match rates\nIdentify and analyse failed geocodes\nCreate interactive maps to visualise spatial and temporal patterns\nUnderstand how geocoding quality affects downstream spatial analysis\nApply geographic masking (geomasking) to protect privacy while preserving spatial patterns\nApply the full geocoding-to-visualisation workflow independently on a new dataset of your choosing"
  },
  {
    "objectID": "ex1.html#background",
    "href": "ex1.html#background",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "",
    "text": "This exercise uses criminal homicides that occurred in Philadelphia during 2025. The dataset includes incident details and address information, but coordinates have been removed. You must geocode these addresses and analyze the spatial and temporal patterns."
  },
  {
    "objectID": "ex1.html#task-1.1-load-the-data",
    "href": "ex1.html#task-1.1-load-the-data",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 1.1: Load the Data",
    "text": "Task 1.1: Load the Data\n\n\nCode\n# Load the homicide dataset and parse the date column once\nhomicides &lt;- read_csv(\"philadelphia_homicides_2025.csv\", show_col_types = FALSE) %&gt;%\n  mutate(dispatch_date = mdy(dispatch_date))\n\n# Examine the structure\nglimpse(homicides)\n\n\nRows: 222\nColumns: 18\n$ the_geom             &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ cartodb_id           &lt;dbl&gt; 127508, 127509, 127510, 127511, 127512, 127513, 1…\n$ the_geom_webmercator &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ objectid             &lt;dbl&gt; 36297680, 36297681, 36297682, 36297683, 36297684,…\n$ dc_dist              &lt;chr&gt; \"08\", \"12\", \"09\", \"12\", \"15\", \"14\", \"15\", \"15\", \"…\n$ psa                  &lt;dbl&gt; 2, 2, 1, 1, 1, 3, 1, 1, 4, 1, 1, 3, 2, 3, 3, 1, 3…\n$ dispatch_date_time   &lt;dttm&gt; 2025-05-05 04:00:00, 2025-06-18 04:00:00, 2025-0…\n$ dispatch_date        &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ dispatch_time        &lt;time&gt; 00:00:00, 00:00:00, 00:00:00, 00:00:00, 00:00:00…\n$ hour                 &lt;dbl&gt; 10, 3, 22, 15, 3, 1, 10, 4, 7, 17, 9, 16, 7, 11, …\n$ dc_key               &lt;dbl&gt; 202508018481, 202512026710, 202509062283, 2025121…\n$ location_block       &lt;chr&gt; \"2800 BLOCK NORCROSS ST\", \"200 BLOCK S CAMAC ST\",…\n$ ucr_general          &lt;dbl&gt; 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,…\n$ text_general_code    &lt;chr&gt; \"Homicide - Criminal\", \"Homicide - Criminal\", \"Ho…\n$ point_x              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ point_y              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ lat                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ lng                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\nCode\n# Display first 10 rows\nkable(head(homicides, 10), caption = \"First 10 homicide incidents\")\n\n\n\nFirst 10 homicide incidents\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nthe_geom\ncartodb_id\nthe_geom_webmercator\nobjectid\ndc_dist\npsa\ndispatch_date_time\ndispatch_date\ndispatch_time\nhour\ndc_key\nlocation_block\nucr_general\ntext_general_code\npoint_x\npoint_y\nlat\nlng\n\n\n\n\nNA\n127508\nNA\n36297680\n08\n2\n2025-05-05 04:00:00\nNA\n00:00:00\n10\n202508018481\n2800 BLOCK NORCROSS ST\n100\nHomicide - Criminal\nNA\nNA\nNA\nNA\n\n\nNA\n127509\nNA\n36297681\n12\n2\n2025-06-18 04:00:00\nNA\n00:00:00\n3\n202512026710\n200 BLOCK S CAMAC ST\n100\nHomicide - Criminal\nNA\nNA\nNA\nNA\n\n\nNA\n127510\nNA\n36297682\n09\n1\n2025-05-26 04:00:00\nNA\n00:00:00\n22\n202509062283\n800 BLOCK LEMON HILL\n100\nHomicide - Criminal\nNA\nNA\nNA\nNA\n\n\nNA\n127511\nNA\n36297683\n12\n1\n2025-12-05 05:00:00\nNA\n00:00:00\n15\n202512106610\n2600 BLOCK MUHFIELD ST\n100\nHomicide - Criminal\nNA\nNA\nNA\nNA\n\n\nNA\n127512\nNA\n36297684\n15\n1\n2025-04-05 04:00:00\nNA\n00:00:00\n3\n202515028892\n4400 BLOCK FRANKFORD A\n100\nHomicide - Criminal\nNA\nNA\nNA\nNA\n\n\nNA\n127513\nNA\n36297685\n14\n3\n2025-09-17 04:00:00\nNA\n00:00:00\n1\n202514067755\n200 BLOCK W RITTENHOUSE\n100\nHomicide - Criminal\nNA\nNA\nNA\nNA\n\n\nNA\n127514\nNA\n36297686\n15\n1\n2025-01-02 05:00:00\nNA\n00:00:00\n10\n202515000310\n1800 BLOCK WAKELNG ST\n100\nHomicide - Criminal\nNA\nNA\nNA\nNA\n\n\nNA\n127515\nNA\n36297687\n15\n1\n2025-06-13 04:00:00\nNA\n00:00:00\n4\n202515054256\n4100 BLOCK FRANKFORD AV\n100\nHomicide - Criminal\nNA\nNA\nNA\nNA\n\n\nNA\n127516\nNA\n36297688\n14\n4\n2025-10-28 04:00:00\nNA\n00:00:00\n7\n202514085742\n1500 BLOCK WADSWORTH ST\n100\nHomicide - Criminal\nNA\nNA\nNA\nNA\n\n\nNA\n127517\nNA\n36297689\n24\n1\n2025-01-14 05:00:00\nNA\n00:00:00\n17\n202524004024\n3300 BLOCK “H” ST\n100\nHomicide - Criminal\nNA\nNA\nNA\nNA\n\n\n\n\n\nQuestion: How many homicide incidents are in the dataset?\nANSWER: There are 222 homicide incidents in the 2025 Philadelphia dataset."
  },
  {
    "objectID": "ex1.html#explore-the-dataset",
    "href": "ex1.html#explore-the-dataset",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Explore the dataset",
    "text": "Explore the dataset\n\nTemporal Patterns: By Hour of Day\n\n\nCode\n# Count incidents by hour (0-23 format)\nhourly_counts &lt;- homicides %&gt;%\n  count(hour, name = \"homicides\") %&gt;%\n  arrange(hour)\n\n# Create bar plot\nggplot(hourly_counts, aes(x = hour, y = homicides)) +\n  geom_col(fill = \"steelblue\", alpha = 0.7) +\n  geom_text(aes(label = homicides), vjust = -0.5, size = 2.5) +\n  scale_x_continuous(breaks = seq(0, 23, 2)) +\n  labs(\n    title = \"Philadelphia Homicides by Hour of Day (2025)\",\n    subtitle = paste(\"Total homicides:\", sum(hourly_counts$homicides)),\n    x = \"Hour (0 = midnight, 23 = 11pm)\",\n    y = \"Number of Homicides\"\n  ) +\n  theme_minimal(base_size = 12) +\n  ylim(0, max(hourly_counts$homicides) * 1.15)\n\n\n\n\n\n\n\n\n\nCode\n# Group into time periods for summary\nhourly_summary &lt;- hourly_counts %&gt;%\n  mutate(\n    time_period = case_when(\n      hour &gt;= 0 & hour &lt; 6 ~ \"Late Night (12am-6am)\",\n      hour &gt;= 6 & hour &lt; 12 ~ \"Morning (6am-12pm)\",\n      hour &gt;= 12 & hour &lt; 18 ~ \"Afternoon (12pm-6pm)\",\n      hour &gt;= 18 & hour &lt; 24 ~ \"Evening (6pm-12am)\"\n    )\n  ) %&gt;%\n  group_by(time_period) %&gt;%\n  summarize(homicides = sum(homicides)) %&gt;%\n  mutate(percentage = round(homicides / sum(homicides) * 100, 1))\n\nkable(hourly_summary,\n      caption = \"Homicides by Time Period\",\n      col.names = c(\"Time Period\", \"Homicides\", \"Percentage\"))\n\n\n\nHomicides by Time Period\n\n\nTime Period\nHomicides\nPercentage\n\n\n\n\nAfternoon (12pm-6pm)\n40\n18.0\n\n\nEvening (6pm-12am)\n79\n35.6\n\n\nLate Night (12am-6am)\n63\n28.4\n\n\nMorning (6am-12pm)\n40\n18.0"
  },
  {
    "objectID": "ex1.html#task-2.1-geocode-with-census-bureau",
    "href": "ex1.html#task-2.1-geocode-with-census-bureau",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 2.1: Geocode with Census Bureau",
    "text": "Task 2.1: Geocode with Census Bureau\n\n\nCode\nhomicides_census &lt;- homicides %&gt;%\n  mutate(\n    clean_address = location_block %&gt;%\n      str_replace(\" BLOCK \", \" \") %&gt;%\n      str_remove_all('\"') %&gt;%                    # Remove quotes\n      str_replace(\" AV$\", \" AVE\") %&gt;%            # Fix truncated AV\n      str_replace(\" A$\", \" AVE\") %&gt;%             # Fix truncated A\n      str_replace(\" ST$\", \" STREET\") %&gt;%         # Expand ST (optional)\n      str_replace(\"WAKELNG\", \"WAKELING\") %&gt;%     # Fix known misspelling\n      str_replace(\"MUHFIELD\", \"MUHLFIELD\"),      # Fix known misspelling\n    full_address = paste(clean_address, \"Philadelphia, PA\")\n  ) %&gt;%\n  geocode(\n    address = full_address,\n    method = \"census\",\n    lat = latitude,\n    long = longitude,\n    verbose = TRUE\n  )\n\n\n\nNumber of Unique Addresses: 209\n\n\nExecuting batch geocoding...\n\n\nBatch limit: 10,000\n\n\nPassing 209 addresses to the US Census batch geocoder\n\n\nQuerying API URL: https://geocoding.geo.census.gov/geocoder/locations/addressbatch\n\n\nPassing the following parameters to the API:\n\n\nformat : \"json\"\n\n\nbenchmark : \"Public_AR_Current\"\n\n\nvintage : \"Current_Current\"\n\n\nQuery completed in: 1.2 seconds\n\n\nCode\n# Check what was added\ncat(\"Columns added by geocoding:\\n\")\n\n\nColumns added by geocoding:\n\n\nCode\nnew_cols &lt;- setdiff(colnames(homicides_census), colnames(homicides))\ncat(paste(new_cols, collapse = \", \"), \"\\n\")\n\n\nclean_address, full_address, latitude, longitude \n\n\nCode\n# Quick success rate check\ncat(\n  \"\\nGeocoding success rate:\",\n  mean(!is.na(homicides_census$latitude)) * 100,\n  \"%\\n\"\n)\n\n\n\nGeocoding success rate: 94.14414 %\n\n\nQuestion: What columns were added by the geocoding process?\nANSWER: The geocode() function adds two columns: latitude and longitude, named by the lat = and long = arguments in the call above."
  },
  {
    "objectID": "ex1.html#task-2.2-calculate-match-rate",
    "href": "ex1.html#task-2.2-calculate-match-rate",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 2.2: Calculate Match Rate",
    "text": "Task 2.2: Calculate Match Rate\n\n\nCode\n# Calculate match rate\nmatch_rate_census &lt;- mean(!is.na(homicides_census$latitude)) * 100\ngeocoded_count &lt;- sum(!is.na(homicides_census$latitude))\nfailed_count &lt;- sum(is.na(homicides_census$latitude))\n\n# Summary statistics\ncat(\"=== CENSUS GEOCODER RESULTS ===\\n\")\n\n\n=== CENSUS GEOCODER RESULTS ===\n\n\nCode\ncat(\"Total addresses:\", nrow(homicides_census), \"\\n\")\n\n\nTotal addresses: 222 \n\n\nCode\ncat(\"Successfully geocoded:\", geocoded_count, \"\\n\")\n\n\nSuccessfully geocoded: 209 \n\n\nCode\ncat(\"Failed to geocode:\", failed_count, \"\\n\")\n\n\nFailed to geocode: 13 \n\n\nCode\ncat(\"Match rate:\", round(match_rate_census, 1), \"%\\n\\n\")\n\n\nMatch rate: 94.1 %\n\n\nQuestion: What is your geocoding match rate with the Census Bureau geocoder?\nANSWER: The match rate is 94.1%.\nNOTE: A typical match rate for US addresses ranges from 85-98%. Block-level addresses (like “2800 BLOCK PROSPECT ST”) may have lower match rates than exact addresses because: - The geocoder must interpolate along the street segment - Some street segments may be missing from TIGER files - Block-level addresses are inherently less precise"
  },
  {
    "objectID": "ex1.html#task-2.3-examine-failed-geocodes",
    "href": "ex1.html#task-2.3-examine-failed-geocodes",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 2.3: Examine Failed Geocodes",
    "text": "Task 2.3: Examine Failed Geocodes\n\n\nCode\nfailed_census &lt;- homicides_census %&gt;%\n  filter(is.na(latitude)) %&gt;%\n  select(objectid, dispatch_date, location_block, dc_key)\n\nkable(\n  head(failed_census, 10),\n  caption = \"Failed Geocodes (first 10)\",\n  col.names = c(\"Object ID\", \"Date\", \"Address\", \"DC Key\")\n)\n\n\n\nFailed Geocodes (first 10)\n\n\nObject ID\nDate\nAddress\nDC Key\n\n\n\n\n36297682\nNA\n800 BLOCK LEMON HILL\n202509062283\n\n\n36297685\nNA\n200 BLOCK W RITTENHOUSE\n202514067755\n\n\n36297693\nNA\n300 BLOCK MARTHA ST\n202524087954\n\n\n36297694\nNA\n4900 BLOCK STENETON AV\n202535090617\n\n\n36297696\nNA\n3700 BLOCK W STERNER ST\n202539001193\n\n\n36297697\nNA\nKELLY MIDVALE AV\n202539008438\n\n\n36300139\nNA\n2500 BLOCK CHADWICK ST\n202522032072\n\n\n36300196\nNA\n5900 BLOCK N LAMBERT ST\n202535091437\n\n\n36300439\nNA\n3300 BLOCK RIDGE AV\n202522080291\n\n\n36300976\nNA\n0 BLOCK N FRAZIER ST\n202519066271\n\n\n\n\n\nCode\nwrite_csv(failed_census, \"failed_geocodes_census.csv\")\ncat(\"\\nSaved\", nrow(failed_census), \"failed addresses to: failed_geocodes_census.csv\\n\")\n\n\n\nSaved 13 failed addresses to: failed_geocodes_census.csv\n\n\nQuestion: List 3-5 examples of addresses that failed to geocode. What patterns do you notice?\nANSWER: Examples of failed addresses:\n\n\nCode\nif(nrow(failed_census) &gt; 0) {\n  failed_census %&gt;% \n    head(5) %&gt;% \n    pull(location_block) %&gt;%\n    cat(sep = \"\\n\")\n} else {\n  cat(\"All addresses geocoded successfully!\")\n}\n\n\n800 BLOCK LEMON HILL\n200 BLOCK W RITTENHOUSE\n300 BLOCK MARTHA ST\n4900 BLOCK STENETON AV\n3700 BLOCK W STERNER ST\n\n\nNOTE: Common patterns in failed geocodes include: - Incomplete street names (e.g., “N” instead of “NORTH”) - Non-standard abbreviations (e.g., “BLVD” vs “BOULEVARD”) - Missing street segments in the TIGER reference database - Intersections rather than specific addresses (e.g., “15TH ST & WALNUT ST”) - Misspellings or unusual street names"
  },
  {
    "objectID": "ex1.html#task-3.1-create-spatial-objects",
    "href": "ex1.html#task-3.1-create-spatial-objects",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 3.1: Create Spatial Objects",
    "text": "Task 3.1: Create Spatial Objects\n\n\nCode\n# Use Census geocoding results; drop cases that failed\nhomicides_sf &lt;- homicides_census %&gt;%\n  filter(!is.na(latitude) & !is.na(longitude)) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326)  # WGS84\n\ncat(\"Successfully created spatial object with\", nrow(homicides_sf), \"homicides\\n\")\n\n\nSuccessfully created spatial object with 209 homicides\n\n\nQuestion: How many homicides were successfully geocoded and included in your spatial object?\nANSWER: 209 homicides were successfully geocoded and converted to a spatial object.\nNOTE: This represents 94.1% of the original 222 homicides. The missing 13 cases (5.9%) could not be mapped due to geocoding failure. If these failures are spatially clustered, our analysis will be biased."
  },
  {
    "objectID": "ex1.html#task-3.2-static-map",
    "href": "ex1.html#task-3.2-static-map",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 3.2: Static Map",
    "text": "Task 3.2: Static Map\n\n\nCode\n# Set up plot parameters\npar(mar = c(4, 4, 3, 1))\n\n# Get bounding box\nbbox &lt;- st_bbox(homicides_sf)\n\n# Create plot\nplot(st_geometry(homicides_sf),\n     pch = 19,\n     col = adjustcolor(\"red\", alpha.f = 0.6),\n     cex = 0.8,\n     main = \"Philadelphia Homicides 2025\",\n     xlab = \"Longitude\",\n     ylab = \"Latitude\",\n     axes = TRUE)\n\n# Add grid\ngrid()\n\n# Add count\ntext(bbox[\"xmin\"], bbox[\"ymax\"], \n     paste(\"n =\", nrow(homicides_sf)), \n     pos = 4, cex = 0.9)\n\n\n\n\n\n\n\n\n\nQuestion: Based on the static map, do homicides appear to be randomly distributed across Philadelphia or are there apparent clusters?\nANSWER: Homicides appear to be spatially clustered rather than randomly distributed. Visual inspection suggests: - Higher concentration in certain areas of the city - Some areas with very few or no homicides - Possible clustering in what appears to be central/north Philadelphia\nNOTE: This visual assessment should be confirmed with formal statistical tests (e.g., Moran's I, Ripley's K-function, or spatial scan statistics). The apparent clustering could reflect: 1. True spatial clustering of homicide risk factors 2. Population density patterns (more people = more potential victims) 3. Spatially varying socioeconomic conditions 4. Geographic variation in policing and reporting"
  },
  {
    "objectID": "ex1.html#task-3.3-interactive-map---basic",
    "href": "ex1.html#task-3.3-interactive-map---basic",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 3.3: Interactive Map - Basic",
    "text": "Task 3.3: Interactive Map - Basic\n\n\nCode\n# Create basic interactive map\nmap_basic &lt;- homicides_sf %&gt;%\n  leaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  addCircleMarkers(\n    popup = ~paste0(\n      \"&lt;strong&gt;Homicide&lt;/strong&gt;&lt;br&gt;\",\n      \"Date: \", dispatch_date, \"&lt;br&gt;\",\n      \"Time: \", hour, \":00&lt;br&gt;\",\n      \"Location: \", location_block, \"&lt;br&gt;\",\n      \"District: \", dc_dist, \"&lt;br&gt;\",\n      \"Object ID: \", objectid\n    ),\n    radius = 4,\n    color = \"darkred\",\n    fillColor = \"red\",\n    fillOpacity = 0.7,\n    weight = 2,\n    label = ~paste(\"District\", dc_dist)\n  ) %&gt;%\n  addScaleBar(position = \"bottomleft\") %&gt;%\n  addMiniMap(\n    toggleDisplay = TRUE,\n    minimized = TRUE,\n    position = \"bottomright\"\n  ) %&gt;%\n  addControl(\n    html = paste0(\"&lt;div style=\\'background: white; padding: 5px; border-radius: 5px;\\'&gt;&lt;strong&gt;Philadelphia Homicides 2025&lt;/strong&gt;&lt;br&gt;n = \", nrow(homicides_sf), \"&lt;/div&gt;\"),\n    position = \"topright\"\n  )\n\n# Display the map\nmap_basic\n\n\n\n\n\n\nCode\n# Save the map\nsaveWidget(map_basic, \"philadelphia_homicides_basic.html\", selfcontained = TRUE)\ncat(\"\\nMap saved to: philadelphia_homicides_basic.html\\n\")\n\n\n\nMap saved to: philadelphia_homicides_basic.html\n\n\nQuestion: Explore the interactive map. Which areas of Philadelphia have the highest concentration of homicides?\nANSWER: Based on interactive exploration, the highest concentrations appear in: - North Philadelphia (Districts 22, 24, 25, 35) - West Philadelphia (Districts 16, 18, 19) - Some concentration in Southwest Philadelphia (District 12)\nNOTE: Students should zoom in and click on individual points to see patterns. Encourage them to: - Look for clustering within districts - Note areas with very few homicides (likely wealthy/suburban areas) - Consider how population density might explain patterns - Think about historical patterns of segregation and disinvestment"
  },
  {
    "objectID": "ex1.html#task-3.4-enhanced-map---time-of-day",
    "href": "ex1.html#task-3.4-enhanced-map---time-of-day",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 3.4: Enhanced Map - Time of Day",
    "text": "Task 3.4: Enhanced Map - Time of Day\n\n\nCode\n# Categorize by time of day\nhomicides_sf &lt;- homicides_sf %&gt;%\n  mutate(\n    time_period = case_when(\n      hour &gt;= 0 & hour &lt; 6 ~ \"Late Night (12am-6am)\",\n      hour &gt;= 6 & hour &lt; 12 ~ \"Morning (6am-12pm)\",\n      hour &gt;= 12 & hour &lt; 18 ~ \"Afternoon (12pm-6pm)\",\n      hour &gt;= 18 & hour &lt; 24 ~ \"Evening (6pm-12am)\"\n    ),\n    time_period = factor(time_period, levels = c(\n      \"Morning (6am-12pm)\",\n      \"Afternoon (12pm-6pm)\",\n      \"Evening (6pm-12am)\",\n      \"Late Night (12am-6am)\"\n    ))\n  )\n\n# Create color palette\ntime_colors &lt;- colorFactor(\n  palette = c(\"#FFC107\", \"#FF9800\", \"#F44336\", \"#880E4F\"),\n  domain = homicides_sf$time_period\n)\n\n# Create map with time periods\nmap_time &lt;- homicides_sf %&gt;%\n  leaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  addCircleMarkers(\n    popup = ~paste0(\n      \"&lt;strong&gt;Homicide&lt;/strong&gt;&lt;br&gt;\",\n      \"Date: \", dispatch_date, \"&lt;br&gt;\",\n      \"Time: \", hour, \":00 (\", time_period, \")&lt;br&gt;\",\n      \"Location: \", location_block, \"&lt;br&gt;\",\n      \"District: \", dc_dist\n    ),\n    radius = 4,\n    color = ~time_colors(time_period),\n    fillColor = ~time_colors(time_period),\n    fillOpacity = 0.8,\n    weight = 2,\n    group = ~time_period\n  ) %&gt;%\n  addLayersControl(\n    overlayGroups = levels(homicides_sf$time_period),\n    options = layersControlOptions(collapsed = FALSE)\n  ) %&gt;%\n  addLegend(\n    position = \"topright\",\n    pal = time_colors,\n    values = ~time_period,\n    title = \"Time of Day\",\n    opacity = 1\n  ) %&gt;%\n  addScaleBar(position = \"bottomleft\")\n\n# Display map\nmap_time\n\n\n\n\n\n\nCode\n# Save\nsaveWidget(map_time, \"philadelphia_homicides_timeofday.html\", selfcontained = TRUE)\ncat(\"\\nMap saved to: philadelphia_homicides_timeofday.html\\n\")\n\n\n\nMap saved to: philadelphia_homicides_timeofday.html\n\n\nQuestion: Toggle the different time periods on/off. Do spatial patterns vary by time of day?\nANSWER: Yes, spatial patterns show temporal variation: - Late night homicides (12am-6am) are the most common and appear concentrated in specific areas - Morning homicides (6am-12pm) are least common and more dispersed - Evening homicides (6pm-12am) show moderate clustering - Some districts show more variation by time than others\nNOTE: This spatiotemporal pattern suggests: 1. Different causal mechanisms may be at work at different times 2. Nighttime economy (bars, clubs) may concentrate risk 3. Targeted interventions could be time-specific 4. Resource allocation (police patrols) should consider temporal patterns"
  },
  {
    "objectID": "ex1.html#task-3.5-map-by-police-district",
    "href": "ex1.html#task-3.5-map-by-police-district",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 3.5: Map by Police District",
    "text": "Task 3.5: Map by Police District\n\n\nCode\n# Count homicides by district\ndistrict_summary &lt;- homicides_sf %&gt;%\n  st_drop_geometry() %&gt;%\n  count(dc_dist, name = \"homicides\") %&gt;%\n  arrange(desc(homicides))\n\nkable(district_summary,\n      caption = \"Homicides by Police District (Geocoded Cases Only)\",\n      col.names = c(\"District\", \"Homicides\"))\n\n\n\nHomicides by Police District (Geocoded Cases Only)\n\n\nDistrict\nHomicides\n\n\n\n\n22\n27\n\n\n25\n25\n\n\n12\n20\n\n\n24\n20\n\n\n35\n15\n\n\n15\n12\n\n\n19\n12\n\n\n39\n12\n\n\n16\n10\n\n\n14\n9\n\n\n18\n8\n\n\n03\n7\n\n\n02\n6\n\n\n17\n6\n\n\n26\n5\n\n\n05\n4\n\n\n08\n4\n\n\n09\n4\n\n\n01\n2\n\n\n07\n1\n\n\n\n\n\nCode\n# Create district-colored map\ndistrict_colors &lt;- colorFactor(\n  palette = \"Set3\",\n  domain = homicides_sf$dc_dist\n)\n\nmap_districts &lt;- homicides_sf %&gt;%\n  leaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  addCircleMarkers(\n    popup = ~paste0(\n      \"&lt;strong&gt;District \", dc_dist, \"&lt;/strong&gt;&lt;br&gt;\",\n      \"Date: \", dispatch_date, \"&lt;br&gt;\",\n      \"Time: \", hour, \":00&lt;br&gt;\",\n      \"Location: \", location_block\n    ),\n    radius = 4,\n    color = ~district_colors(dc_dist),\n    fillColor = ~district_colors(dc_dist),\n    fillOpacity = 0.7,\n    weight = 2,\n    group = ~paste(\"District\", dc_dist)\n  ) %&gt;%\n  addLayersControl(\n    overlayGroups = unique(paste(\"District\", sort(homicides_sf$dc_dist))),\n    options = layersControlOptions(collapsed = FALSE)\n  ) %&gt;%\n  addLegend(\n    position = \"topright\",\n    pal = district_colors,\n    values = ~dc_dist,\n    title = \"Police District\",\n    opacity = 1\n  )\n\nmap_districts\n\n\n\n\n\n\nQuestion: Which 3 police districts have the highest number of homicides?\nANSWER: Based on the district summary table: 1. District 22: 27 homicides 2. District 25: 25 homicides 3. District 12: 20 homicides\nNOTE: These top districts account for 34.4% of all geocoded homicides. This concentration suggests resource allocation should be targeted to high-burden areas."
  },
  {
    "objectID": "ex1.html#task-4.1-homicides-by-time-of-day",
    "href": "ex1.html#task-4.1-homicides-by-time-of-day",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 4.1: Homicides by Time of Day",
    "text": "Task 4.1: Homicides by Time of Day\n\n\nCode\n# Count by time period\ntime_summary &lt;- homicides_sf %&gt;%\n  st_drop_geometry() %&gt;%\n  count(time_period) %&gt;%\n  mutate(\n    percentage = n / sum(n) * 100\n  )\n\nkable(time_summary,\n      caption = \"Homicides by Time of Day\",\n      col.names = c(\"Time Period\", \"Count\", \"Percentage\"),\n      digits = c(0, 0, 1))\n\n\n\nHomicides by Time of Day\n\n\nTime Period\nCount\nPercentage\n\n\n\n\nMorning (6am-12pm)\n36\n17.2\n\n\nAfternoon (12pm-6pm)\n38\n18.2\n\n\nEvening (6pm-12am)\n74\n35.4\n\n\nLate Night (12am-6am)\n61\n29.2\n\n\n\n\n\nCode\n# Visualize\nggplot(time_summary, aes(x = time_period, y = n, fill = time_period)) +\n  geom_col(show.legend = FALSE) +\n  geom_text(aes(label = paste0(n, \"\\n(\", round(percentage, 1), \"%)\")), \n            vjust = -0.5, size = 4) +\n  scale_fill_manual(values = c(\"#FFC107\", \"#FF9800\", \"#F44336\", \"#880E4F\")) +\n  labs(\n    title = \"Philadelphia Homicides by Time of Day (2025)\",\n    subtitle = paste(\"Total geocoded homicides:\", sum(time_summary$n)),\n    x = \"Time Period\",\n    y = \"Number of Homicides\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(axis.text.x = element_text(angle = 20, hjust = 1)) +\n  ylim(0, max(time_summary$n) * 1.15)\n\n\n\n\n\n\n\n\n\nQuestion: During which time period do most homicides occur?\nANSWER: Most homicides occur during Evening (6pm-12am), accounting for 35.4% of all homicides (n = 74).\nNOTE: The concentration of homicides in late night/evening hours suggests: - Role of nighttime economy (bars, social gatherings) - Reduced guardianship (fewer witnesses, police) - Alcohol involvement likely - Different intervention strategies needed for different times"
  },
  {
    "objectID": "ex1.html#question-geocoding-quality-assessment",
    "href": "ex1.html#question-geocoding-quality-assessment",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Question: Geocoding Quality Assessment",
    "text": "Question: Geocoding Quality Assessment\nReflect on the geocoding process. What percentage of addresses could NOT be geocoded? How might these missing locations affect your spatial analysis?\nANSWER:\n\n\nCode\ntotal_incidents &lt;- nrow(homicides)\nsuccessfully_geocoded &lt;- nrow(homicides_sf)\nfailed_to_geocode &lt;- total_incidents - successfully_geocoded\nfailure_rate &lt;- (failed_to_geocode / total_incidents) * 100\n\ncat(\"Geocoding Summary:\\n\")\n\n\nGeocoding Summary:\n\n\nCode\ncat(\"Total incidents:\", total_incidents, \"\\n\")\n\n\nTotal incidents: 222 \n\n\nCode\ncat(\"Successfully geocoded:\", successfully_geocoded, \"(\", \n    round(100 - failure_rate, 1), \"%)\\n\")\n\n\nSuccessfully geocoded: 209 ( 94.1 %)\n\n\nCode\ncat(\"Failed to geocode:\", failed_to_geocode, \"(\", \n    round(failure_rate, 1), \"%)\\n\\n\")\n\n\nFailed to geocode: 13 ( 5.9 %)\n\n\nImpact on spatial analysis:\n\nReduced sample size: We lost 13 cases (5.9%), reducing statistical power to detect spatial patterns.\nPotential spatial bias:\n\nIf geocoding failures are randomly distributed → estimates remain unbiased but less precise\nIf failures cluster spatially → systematic bias in hot spot detection\nRural or newly developed areas often have lower geocoding rates\n\nDistrict-level effects:\n\nSome districts may be underrepresented if geocoding failures concentrated there\nRate calculations (homicides per capita) will be underestimated in affected areas\n\nCannot assess patterns in failed areas:\n\nHot spots may exist in areas with many failures but go undetected\nResource allocation decisions could be biased against these areas\n\n\nNOTE: This is why the Zimmerman et al. (2008) paper is so important - it showed that geocoding failures ARE spatially clustered, and when disease is associated with geocoding failure (e.g., rural disease + rural geocoding failure), statistical power drops by 50-70%!"
  },
  {
    "objectID": "ex1.html#question-positional-uncertainty-from-block-level-addresses",
    "href": "ex1.html#question-positional-uncertainty-from-block-level-addresses",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Question: Positional Uncertainty from Block-Level Addresses",
    "text": "Question: Positional Uncertainty from Block-Level Addresses\nThe addresses in this dataset are recorded at the block level (e.g., “2800 BLOCK PROSPECT ST”). The Census geocoder places each address somewhere along the corresponding street segment, but the true incident location could be anywhere on that block — typically a 50–200 m range. Discuss how this inherent positional uncertainty could affect each of the following analyses:\na) Identifying homicide hot spots?\nANSWER: A 50–200 m positional uncertainty can:\n\nBlur the true boundaries of spatial clusters\nMove cases in or out of a detected cluster depending on where along the block they are placed\nReduce statistical power, making it harder to detect real clusters\nCreate spurious clusters if the geocoder systematically places block-level addresses at the same interpolation point\nBe particularly problematic for small-area clusters (radius &lt; 500 m)\n\nb) Calculating distance to the nearest police station?\nANSWER:\n\nThe positional uncertainty translates directly into roughly the same magnitude of error in any distance calculation\nAn incident near the boundary of a 500 m buffer around a station could be misclassified as inside or outside that buffer\nThis affects accessibility analyses and response-time estimates\nAreas with many block-level addresses near station boundaries are most vulnerable to this bias\n\nc) Determining whether a homicide occurred within a specific neighbourhood?\nANSWER:\n\nCensus tracts are typically 1–4 blocks across; a 50–200 m shift can easily cross a tract boundary\nIncidents near neighbourhood borders may be assigned to the wrong administrative unit\nThis biases rate calculations for the affected neighbourhoods\nSmall neighbourhoods and narrow boundary zones are at highest risk of misclassification\n\nNOTE: Connect this to the Olson et al. (2006) paper — they showed that aggregating to census tract centroids (which introduces comparable positional error) reduced cluster-detection power by 20–30%. Also relevant: Jacquez (2012) documents mean positional errors of 58–614 m across different geocoding settings."
  },
  {
    "objectID": "ex1.html#question-spatial-patterns",
    "href": "ex1.html#question-spatial-patterns",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Question: Spatial Patterns",
    "text": "Question: Spatial Patterns\nBased on your maps and analyses, describe the spatial distribution of homicides in Philadelphia. Are they concentrated in certain areas or evenly distributed?\nANSWER:\nHomicides in Philadelphia 2025 show strong spatial concentration:\n\nGeographic concentration:\n\nTop 3 districts account for 34.4% of all homicides\nClear visual clustering in North and West Philadelphia\nSome areas have virtually no homicides\n\nSpatial heterogeneity:\n\nNot all areas within high-burden districts equally affected\nMicro-level clustering within districts visible on interactive maps\nSome street segments/blocks have multiple incidents\n\nPossible explanations (would require additional data to confirm):\n\nCorrelation with socioeconomic disadvantage\nHistorical patterns of segregation and disinvestment\nPopulation density variations\nDrug market locations\nGang territory boundaries\n\nStatistical confirmation needed:\n\nVisual patterns should be tested with Moran's I or spatial scan statistics\nNeed to account for population at risk (denominators)\nConsider other spatial risk factors\n\n\nNOTE: This provides teachable moment about:\n\nEcological fallacy (area-level patterns ≠ individual risk)\nNeed for appropriate denominators (incidents per capita, not just counts)\nImportance of theory in interpreting spatial patterns\nEthics of mapping stigmatizing outcomes"
  },
  {
    "objectID": "ex1.html#question-temporal-patterns",
    "href": "ex1.html#question-temporal-patterns",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Question: Temporal Patterns",
    "text": "Question: Temporal Patterns\nDescribe any temporal patterns you observed (time of day, day of week, monthly trends). How might these patterns inform public safety strategies?\nANSWER:\nKey temporal patterns:\n\nTime of day: 35.4% of homicides occur during Evening (6pm-12am)\n\nSuggests role of nighttime economy, alcohol, reduced guardianship\n\nDay of week:\n\n\n\nCode\nif(exists(\"weekend_avg\") && weekend_avg &gt; weekday_avg) {\n  cat(\"   - Weekend elevation (\", round(weekend_avg, 1), \" vs \", \n      round(weekday_avg, 1), \" on weekdays)\\n\", sep=\"\")\n  cat(\"   - Peak on \", homicides_dow$day_of_week[which.max(homicides_dow$n)], \n      \" (\", max(homicides_dow$n), \" homicides)\\n\", sep=\"\")\n}\n\n\n\nSeasonal pattern:\n\n\n\nCode\nif(exists(\"summer_avg\") && summer_avg &gt; winter_avg) {\n  cat(\"   - Summer months show \", round(summer_avg/winter_avg, 1), \n      \"× more homicides than winter\\n\", sep=\"\")\n}\n\n\nImplications for public safety strategies:\n\nTemporal resource allocation:\n\nConcentrate patrols during high-risk hours (Evening (6pm-12am))\nIncrease weekend staffing\nSeasonal surge capacity for summer months\n\nPlace-based interventions:\n\nTarget nightlife districts during peak hours\nHot spot policing in specific locations at specific times\n“Pulling levers” strategies focused on high-risk times\n\nPrevention programs:\n\nViolence interruption programs active during high-risk hours\nCommunity events to provide alternative activities\nCooling centers in summer (if heat-violence link confirmed)\n\nData-driven scheduling:\n\nShift schedules based on temporal patterns\nPredictive policing (with appropriate safeguards)\nReal-time resource deployment\n\n\nNOTE: Emphasize:\n\nTemporal patterns provide actionable intelligence\nBut must be combined with spatial patterns (spatiotemporal analysis)\nEthical concerns about over-policing\nNeed for root cause approaches, not just enforcement"
  },
  {
    "objectID": "ex1.html#introduction-to-geomasking",
    "href": "ex1.html#introduction-to-geomasking",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Introduction to Geomasking",
    "text": "Introduction to Geomasking\nWe have discussed the ethical considerations of working with sensitive location data. Even though our Philadelphia homicide dataset uses block-level addresses rather than exact locations, the combination of date, time, and approximate location could potentially allow re-identification of victims through news reports or public records.\nGeographic masking (or geomasking) is a family of techniques that deliberately introduce positional error to protect privacy while preserving spatial patterns for analysis. The fundamental trade-off is:\n\nMore displacement → Better privacy protection → Less analytical precision\nLess displacement → Weaker privacy protection → Better analytical precision\n\nThe most straightforward approach is random perturbation, where each point is displaced by a random distance in a random direction."
  },
  {
    "objectID": "ex1.html#the-random-perturbation-method",
    "href": "ex1.html#the-random-perturbation-method",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "The Random Perturbation Method",
    "text": "The Random Perturbation Method\nRandom perturbation works by:\n\nGenerating a random angle θ between 0° and 360°\nGenerating a random distance d between 0 and a maximum threshold (e.g., 100 meters)\nDisplacing each point by distance d in direction θ\n\nThis creates a “cloud of uncertainty” around each true location. An attacker who obtains the masked coordinates cannot know if the true location is north, south, east, or west of the displayed point—only that it lies somewhere within the masking radius."
  },
  {
    "objectID": "ex1.html#task-6.1-apply-random-perturbation-to-philadelphia-homicides",
    "href": "ex1.html#task-6.1-apply-random-perturbation-to-philadelphia-homicides",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 6.1: Apply Random Perturbation to Philadelphia Homicides",
    "text": "Task 6.1: Apply Random Perturbation to Philadelphia Homicides\nWe will mask the homicide locations using a 500-meter threshold. This value is chosen because:\n\nIt exceeds the ~50m positional uncertainty already present from block-level geocoding\nIt provides meaningful privacy protection (roughly one city block)\nIt preserves neighborhood-level spatial patterns\nIt is consistent with common geomasking practice in public health research\n\n\n\nCode\n# Function to apply random perturbation geomasking\n# Inputs:\n#   sf_object: an sf object with point geometries\n#   max_distance_m: maximum displacement distance in meters\n# Returns:\n#   sf object with perturbed coordinates\n\ngeomask_random_perturbation &lt;- function(sf_object, max_distance_m) {\n  \n  # Ensure we have point geometries\n  if (!all(st_geometry_type(sf_object) == \"POINT\")) {\n    stop(\"Input must contain only POINT geometries\")\n  }\n  \n  n_points &lt;- nrow(sf_object)\n  \n  # Generate random angles (0 to 2*pi radians)\n  random_angles &lt;- runif(n_points, 0, 2 * pi)\n  \n  # Generate random distances (0 to max_distance_m)\n  random_distances &lt;- runif(n_points, 0, max_distance_m)\n  \n  # Calculate displacement in x and y (in meters)\n  dx_m &lt;- random_distances * cos(random_angles)\n  dy_m &lt;- random_distances * sin(random_angles)\n  \n  # Get current coordinates\n  coords &lt;- st_coordinates(sf_object)\n  \n  # Convert meter displacement to degrees (approximate)\n  # At Philadelphia's latitude (~40°N):\n  # 1 degree latitude ≈ 111,000 m\n  # 1 degree longitude ≈ 85,000 m (111,000 * cos(40°))\n  lat_center &lt;- mean(coords[, 2])\n  meters_per_deg_lat &lt;- 111000\n  meters_per_deg_lon &lt;- 111000 * cos(lat_center * pi / 180)\n  \n dx_deg &lt;- dx_m / meters_per_deg_lon\n  dy_deg &lt;- dy_m / meters_per_deg_lat\n  \n  # Apply displacement\n  new_coords &lt;- coords\n  new_coords[, 1] &lt;- coords[, 1] + dx_deg\n  new_coords[, 2] &lt;- coords[, 2] + dy_deg\n  \n  # Create new sf object with masked coordinates\n  masked_sf &lt;- sf_object\n  st_geometry(masked_sf) &lt;- st_sfc(\n    lapply(1:n_points, function(i) st_point(new_coords[i, ])),\n    crs = st_crs(sf_object)\n  )\n  \n  # Store the displacement distances for analysis\n  masked_sf$mask_distance_m &lt;- random_distances\n  masked_sf$mask_angle_deg &lt;- random_angles * 180 / pi\n  \n  return(masked_sf)\n}\n\n\n\n\nCode\n# Set seed for reproducibility (remove in production for true randomness)\nset.seed(42)\n\n# Apply 100-meter random perturbation\nhomicides_masked &lt;- geomask_random_perturbation(homicides_sf, max_distance_m = 500)\n\n# Summary of displacement distances\ncat(\"=== GEOMASKING SUMMARY ===\\n\")\n\n\n=== GEOMASKING SUMMARY ===\n\n\nCode\ncat(\"Masking threshold: 100 meters\\n\")\n\n\nMasking threshold: 100 meters\n\n\nCode\ncat(\"Points masked:\", nrow(homicides_masked), \"\\n\")\n\n\nPoints masked: 209 \n\n\nCode\ncat(\"\\nDisplacement distances (meters):\\n\")\n\n\n\nDisplacement distances (meters):\n\n\nCode\ncat(\"  Min:\", round(min(homicides_masked$mask_distance_m), 1), \"\\n\")\n\n\n  Min: 1.2 \n\n\nCode\ncat(\"  Mean:\", round(mean(homicides_masked$mask_distance_m), 1), \"\\n\")\n\n\n  Mean: 231.3 \n\n\nCode\ncat(\"  Max:\", round(max(homicides_masked$mask_distance_m), 1), \"\\n\")\n\n\n  Max: 498.3 \n\n\n\n\nCode\n# Visualize the distribution of displacement distances\nggplot(homicides_masked, aes(x = mask_distance_m)) +\n  geom_histogram(bins = 20, fill = \"steelblue\", color = \"white\", alpha = 0.7) +\n  geom_vline(xintercept = mean(homicides_masked$mask_distance_m), \n             color = \"red\", linetype = \"dashed\", size = 1) +\n  annotate(\"text\", x = mean(homicides_masked$mask_distance_m) + 5, y = Inf, \n           label = paste(\"Mean =\", round(mean(homicides_masked$mask_distance_m), 1), \"m\"),\n           vjust = 2, hjust = 0, color = \"red\") +\n  labs(\n    title = \"Distribution of Random Perturbation Distances\",\n    subtitle = \"100-meter maximum threshold\",\n    x = \"Displacement Distance (meters)\",\n    y = \"Count\"\n  ) +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\nQuestion: Why is the mean displacement approximately 67 meters rather than 50 meters (half of 100)?\nANSWER: This is because we are sampling uniformly across a circular area, not along a line. Points near the edge of the circle have more “area” to sample from than points near the center. The expected mean distance for uniform random sampling within a circle of radius r is (2/3)r ≈ 0.67r. With r = 100m, the expected mean is ~67m."
  },
  {
    "objectID": "ex1.html#task-6.2-compare-original-and-masked-locations",
    "href": "ex1.html#task-6.2-compare-original-and-masked-locations",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 6.2: Compare Original and Masked Locations",
    "text": "Task 6.2: Compare Original and Masked Locations\n\n\nCode\n# Create side-by-side comparison map\n\n# Get coordinates for both datasets\noriginal_coords &lt;- st_coordinates(homicides_sf)\nmasked_coords &lt;- st_coordinates(homicides_masked)\n\n# Create comparison data frame\ncomparison_df &lt;- data.frame(\n  orig_lon = original_coords[, 1],\n  orig_lat = original_coords[, 2],\n  mask_lon = masked_coords[, 1],\n  mask_lat = masked_coords[, 2],\n  displacement = homicides_masked$mask_distance_m\n)\n\n# Create line geometries connecting original to masked locations\ndisplacement_lines &lt;- lapply(1:nrow(comparison_df), function(i) {\n  st_linestring(matrix(\n    c(comparison_df$orig_lon[i], comparison_df$orig_lat[i],\n      comparison_df$mask_lon[i], comparison_df$mask_lat[i]),\n    ncol = 2, byrow = TRUE\n  ))\n})\n\ndisplacement_sf &lt;- st_sf(\n  displacement_m = comparison_df$displacement,\n  geometry = st_sfc(displacement_lines, crs = 4326)\n)\n\n# Interactive comparison map with both layers\nmap_comparison &lt;- leaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  \n  # Displacement lines (gray, dashed)\n  addPolylines(\n    data = displacement_sf,\n    color = \"orange\",\n    weight = 2,\n    opacity = 0.5,\n    dashArray = \"3,3\",\n    group = \"Displacement Lines\",\n    popup = ~paste0(\"Displacement: \", round(displacement_m, 1), \" m\")\n  ) %&gt;%\n  \n  # Original locations (red)\n  addCircleMarkers(\n    data = homicides_sf,\n    radius = 5,\n    color = \"red\",\n    fillColor = \"red\",\n    fillOpacity = 0.6,\n    weight = 1,\n    group = \"Original Locations\",\n    popup = ~paste0(\n      \"&lt;strong&gt;Original Location&lt;/strong&gt;&lt;br&gt;\",\n      \"Date: \", dispatch_date, \"&lt;br&gt;\",\n      \"Block: \", location_block\n    )\n  ) %&gt;%\n  \n  # Masked locations (blue)\n  addCircleMarkers(\n    data = homicides_masked,\n    radius = 5,\n    color = \"blue\",\n    fillColor = \"blue\",\n    fillOpacity = 0.6,\n    weight = 1,\n    group = \"Masked Locations (100m)\",\n    popup = ~paste0(\n      \"&lt;strong&gt;Masked Location&lt;/strong&gt;&lt;br&gt;\",\n      \"Displacement: \", round(mask_distance_m, 1), \" m&lt;br&gt;\",\n      \"Direction: \", round(mask_angle_deg, 0), \"°\"\n    )\n  ) %&gt;%\n  \n  # Layer control\n  addLayersControl(\n    overlayGroups = c(\"Original Locations\", \"Masked Locations (100m)\", \"Displacement Lines\"),\n    options = layersControlOptions(collapsed = FALSE)\n  ) %&gt;%\n  \n  addLegend(\n    position = \"topright\",\n    colors = c(\"red\", \"blue\", \"gray\"),\n    labels = c(\"Original\", \"Masked (100m)\", \"Displacement\"),\n    title = \"Location Type\"\n  ) %&gt;%\n  \n  addScaleBar(position = \"bottomleft\")\n\nmap_comparison\n\n\n\n\n\n\nCode\n# Save the comparison map\nsaveWidget(map_comparison, \"philadelphia_homicides_masked_comparison.html\", selfcontained = TRUE)\ncat(\"\\nComparison map saved to: philadelphia_homicides_masked_comparison.html\\n\")\n\n\n\nComparison map saved to: philadelphia_homicides_masked_comparison.html\n\n\n\n**Question:** Toggle the layers on and off to compare the original and masked locations. At the city-wide scale, can you visually distinguish between them? What about when you zoom in to a single neighborhood?\n\n**ANSWER:** At the city-wide scale, the overall spatial pattern (clustering in North and West Philadelphia) is preserved—the masked and original point clouds appear nearly identical. However, when you zoom in to a single neighborhood or block, individual points have clearly shifted. Some points that were on one side of a street now appear on the other side. This demonstrates the key principle of geomasking: **macro-level patterns are preserved while micro-level precision is sacrificed for privacy**.\n\n## Task 6.3: Assess Impact on Spatial Analysis\n\nLet's quantify how geomasking affects a common spatial analysis: counting incidents within police districts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load Philadelphia police district boundaries (if available)\n# For this exercise, we'll use the district codes already in the data\n# and show how point-in-polygon assignments might change\n\n# Count by district - original\ndistrict_original &lt;- homicides_sf %&gt;%\n  st_drop_geometry() %&gt;%\n  count(dc_dist, name = \"original_count\")\n\n# Count by district - masked (using original district assignments)\n# Note: In practice, you would re-run point-in-polygon with masked coordinates\ndistrict_masked &lt;- homicides_masked %&gt;%\n  st_drop_geometry() %&gt;%\n  count(dc_dist, name = \"masked_count\")\n\n# Compare\ndistrict_compare &lt;- district_original %&gt;%\n  left_join(district_masked, by = \"dc_dist\") %&gt;%\n  mutate(\n    difference = masked_count - original_count,\n    pct_change = round((difference / original_count) * 100, 1)\n  )\n\nkable(district_compare,\n      caption = \"District Counts: Original vs. Masked Locations\",\n      col.names = c(\"District\", \"Original\", \"Masked\", \"Difference\", \"% Change\"))\n\n\nDistrict Counts: Original vs. Masked Locations\n\n\nDistrict\nOriginal\nMasked\nDifference\n% Change\n\n\n\n\n01\n2\n2\n0\n0\n\n\n02\n6\n6\n0\n0\n\n\n03\n7\n7\n0\n0\n\n\n05\n4\n4\n0\n0\n\n\n07\n1\n1\n0\n0\n\n\n08\n4\n4\n0\n0\n\n\n09\n4\n4\n0\n0\n\n\n12\n20\n20\n0\n0\n\n\n14\n9\n9\n0\n0\n\n\n15\n12\n12\n0\n0\n\n\n16\n10\n10\n0\n0\n\n\n17\n6\n6\n0\n0\n\n\n18\n8\n8\n0\n0\n\n\n19\n12\n12\n0\n0\n\n\n22\n27\n27\n0\n0\n\n\n24\n20\n20\n0\n0\n\n\n25\n25\n25\n0\n0\n\n\n26\n5\n5\n0\n0\n\n\n35\n15\n15\n0\n0\n\n\n39\n12\n12\n0\n0\n\n\n\n\n:::\nNOTE: In this comparison, we used the original district assignments for both datasets. In a real scenario where you only have masked coordinates, you would need to perform point-in-polygon analysis with the masked points, which could result in some boundary-crossing misclassifications. With a 100m masking threshold, points within ~100m of a district boundary could be assigned to the wrong district."
  },
  {
    "objectID": "ex1.html#task-6.4-save-masked-dataset",
    "href": "ex1.html#task-6.4-save-masked-dataset",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Task 6.4: Save Masked Dataset",
    "text": "Task 6.4: Save Masked Dataset\n\n\nCode\n# Create a version suitable for public release\nhomicides_public &lt;- homicides_masked %&gt;%\n  select(\n    objectid,\n    # Remove exact date - keep only month for temporal analysis\n    month = dispatch_date,\n    time_period,\n    dc_dist,\n    # Geometry is already masked\n  ) %&gt;%\n  mutate(\n    month = floor_date(month, \"month\")  # Round to first of month\n  )\n\n# Remove the masking metadata (don't reveal displacement distances!)\nhomicides_public$mask_distance_m &lt;- NULL\nhomicides_public$mask_angle_deg &lt;- NULL\n\n# Save as GeoJSON for sharing\nst_write(homicides_public, \"philadelphia_homicides_masked_public.geojson\", \n         delete_dsn = TRUE, quiet = TRUE)\n\ncat(\"Public release dataset saved to: philadelphia_homicides_masked_public.geojson\\n\")\n\n\nPublic release dataset saved to: philadelphia_homicides_masked_public.geojson\n\n\nCode\ncat(\"Records:\", nrow(homicides_public), \"\\n\")\n\n\nRecords: 209 \n\n\nCode\ncat(\"Variables retained: objectid, month, time_period, dc_dist, geometry\\n\")\n\n\nVariables retained: objectid, month, time_period, dc_dist, geometry\n\n\nCode\ncat(\"\\nPrivacy protections applied:\\n\")\n\n\n\nPrivacy protections applied:\n\n\nCode\ncat(\"  ✓ 100m random spatial perturbation\\n\")\n\n\n  ✓ 100m random spatial perturbation\n\n\nCode\ncat(\"  ✓ Dates aggregated to month\\n\")\n\n\n  ✓ Dates aggregated to month\n\n\nCode\ncat(\"  ✓ Exact addresses removed\\n\")\n\n\n  ✓ Exact addresses removed"
  },
  {
    "objectID": "ex1.html#reflection-choosing-a-masking-threshold",
    "href": "ex1.html#reflection-choosing-a-masking-threshold",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "Reflection: Choosing a Masking Threshold",
    "text": "Reflection: Choosing a Masking Threshold\nQuestion: We used 500 meters as our masking threshold. Discuss the trade-offs involved in choosing this value. Under what circumstances might you choose a larger threshold (e.g., 1000m)? A smaller one (e.g., 25m)?\nANSWER:\nArguments for a larger threshold (e.g., 1000m): - Highly sensitive data (e.g., HIV cases, domestic violence) - Rural areas where 500m might still identify a single property - When only regional patterns matter, not neighborhood-level - When re-identification risk is high (small population, rare event) - When data will be publicly released without access controls\nArguments for a smaller threshold (e.g., 25m): - When spatial precision is critical for the analysis (e.g., environmental exposure assessment) - When data will remain within a secure research environment - Urban areas with high population density (many potential “matches” within small radius) - When other privacy protections are already in place (temporal aggregation, attribute suppression) - When the original data already has substantial positional error (block-level geocoding)\nKey principle: The masking threshold should be proportional to the privacy risk and inversely proportional to the analytical precision required. There is no universal “correct” value—it depends on context.\nNOTE: Connect this to the Armstrong et al. (1999) paper in the references, which provides a comprehensive framework for evaluating geomasking methods and their trade-offs."
  },
  {
    "objectID": "ex1.html#choose-a-dataset",
    "href": "ex1.html#choose-a-dataset",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "7.1 Choose a Dataset",
    "text": "7.1 Choose a Dataset\nFind a publicly available dataset that contains address-level location information that you can geocode. Good sources include:\n\nCity open-data portals (e.g. Philadelphia OpenData, NYC Open Data, Chicago Data Portal)\nFBI Uniform Crime Reporting (UCR) downloads\nCDC / state health-department disease-surveillance files\nEPA enforcement or facility-location records\nAny other source that interests you and contains US addresses\n\nRequirements: - At least 50 geocodable addresses - Addresses should be in a single metropolitan area (keeps the maps readable) - The dataset should have at least one categorical or temporal variable you can use to colour or layer a map\nQuestion: Describe your dataset. What is the source? How many records does it contain? What variables are available? Why did you choose it?"
  },
  {
    "objectID": "ex1.html#geocode-with-the-census-bureau",
    "href": "ex1.html#geocode-with-the-census-bureau",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "7.2 Geocode with the Census Bureau",
    "text": "7.2 Geocode with the Census Bureau\nAdapt the code from Part 2 to geocode your new dataset.\n\n\nCode\n# --- TEMPLATE — adapt column names to your data ---\nyour_data_geocoded &lt;- your_data %&gt;%\n  mutate(\n    full_address = paste(ADDRESS_COLUMN, \"CITY, STATE\")\n  ) %&gt;%\n  geocode(\n    address = full_address,\n    method  = \"census\",\n    lat     = latitude,\n    long    = longitude,\n    verbose = TRUE\n  )\n\n\nQuestion: What is your match rate? How does it compare to the Philadelphia homicide dataset? If it differs, offer at least two plausible explanations (think about address format, geographic coverage of TIGER files, etc.)."
  },
  {
    "objectID": "ex1.html#examine-your-failed-geocodes",
    "href": "ex1.html#examine-your-failed-geocodes",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "7.3 Examine Your Failed Geocodes",
    "text": "7.3 Examine Your Failed Geocodes\n\n\nCode\n# --- TEMPLATE ---\nyour_failed &lt;- your_data_geocoded %&gt;%\n  filter(is.na(latitude))\n\nkable(head(your_failed, 10))\n\n\nQuestion: What patterns do you see in the addresses that failed? Are the failures random, or do they cluster by neighbourhood, address type, or some other feature?"
  },
  {
    "objectID": "ex1.html#map-your-data",
    "href": "ex1.html#map-your-data",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "7.4 Map Your Data",
    "text": "7.4 Map Your Data\nCreate at least two maps:\n\nA basic point map of all successfully geocoded records.\nAn enhanced map that uses colour or layer toggling to show variation by a categorical or temporal variable in your dataset.\n\n\n\nCode\n# --- TEMPLATE: basic map ---\nlibrary(sf)\nlibrary(leaflet)\n\nyour_sf &lt;- your_data_geocoded %&gt;%\n  filter(!is.na(latitude)) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\nyour_sf %&gt;%\n  leaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  addCircleMarkers(radius = 5, color = \"steelblue\", fillOpacity = 0.7)\n\n\nQuestion: Describe the spatial pattern you observe. Are the records clustered, or spread evenly? Which areas have the highest and lowest concentrations?"
  },
  {
    "objectID": "ex1.html#reflection",
    "href": "ex1.html#reflection",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "7.5 Reflection",
    "text": "7.5 Reflection\nQuestion: Compare your experience geocoding and mapping this new dataset to the Philadelphia homicide exercise. Address at least three of the following:\n\nHow did your match rate compare, and why?\nWere the spatial patterns you observed surprising? What might explain them?\nWhat ethical considerations apply to your dataset? (Think about privacy, stigmatisation, potential for misuse.)\nIf you were to publish a map of your data, what additional steps would you take before doing so?\nWhat limitations does positional uncertainty introduce for the specific analyses one might do with your dataset?"
  },
  {
    "objectID": "ex1.html#apply-geographic-masking-to-your-data",
    "href": "ex1.html#apply-geographic-masking-to-your-data",
    "title": "Exercise 1: Geocoding Exercise: Philadelphia Homicides 2025",
    "section": "7.6 Apply Geographic Masking to Your Data",
    "text": "7.6 Apply Geographic Masking to Your Data\nNow apply random perturbation geomasking to your geocoded dataset. Unlike the Philadelphia exercise where we specified a 500-meter threshold, you must determine an appropriate threshold for your specific data.\n\nStep 1: Choose Your Masking Threshold\nBefore writing any code, consider these factors:\n\nSensitivity of the data: How harmful would re-identification be?\n\nMedical data, crime victimization, domestic violence → larger threshold\nRestaurant inspections, business locations → smaller threshold (or none)\n\nGeographic context: What does distance mean in your study area?\n\nRural area with dispersed properties → larger threshold (100m might identify a single farm)\nDense urban area → smaller threshold may suffice (many potential “matches” nearby)\n\nAnalytical requirements: What spatial precision do you need?\n\nNeighborhood-level analysis → can tolerate 200-500m masking\nStreet-level or parcel-level analysis → masking may compromise results\n\nExisting positional uncertainty: How accurate was your geocoding?\n\nIf geocoding already introduced ~100m error, adding 25m masking adds little privacy\nConsider masking threshold relative to existing uncertainty\n\nOther privacy protections: What else have you done?\n\nIf dates are aggregated and attributes removed, spatial masking can be smaller\nIf full attributes retained, spatial masking should be larger\n\n\nQuestion: What masking threshold will you use for your dataset? Justify your choice by addressing at least three of the factors above.\nYOUR ANSWER: [Write your threshold choice and justification here]\n\n\n\nStep 2: Apply Geomasking\nUse the geomask_random_perturbation() function from Part 6.5 to mask your data.\n\n\nCode\n# --- TEMPLATE: Apply geomasking to your data ---\n\n# First, ensure your data is an sf object\nyour_sf &lt;- your_data_geocoded %&gt;%\n  filter(!is.na(latitude)) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\n# Set your chosen threshold (in meters)\nmy_threshold &lt;- ___  # &lt;-- Enter your threshold here\n\n# Apply random perturbation\nyour_masked &lt;- geomask_random_perturbation(your_sf, max_distance_m = my_threshold)\n\n# Summary\ncat(\"Masking threshold:\", my_threshold, \"meters\\n\")\ncat(\"Points masked:\", nrow(your_masked), \"\\n\")\ncat(\"Mean displacement:\", round(mean(your_masked$mask_distance_m), 1), \"m\\n\")\n\n\n\n\n\nStep 3: Compare Original and Masked Locations\nCreate a map comparing your original and masked locations, similar to Task 6.2.\n\n\nCode\n# --- TEMPLATE: Comparison map ---\nleaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  addCircleMarkers(\n    data = your_sf,\n    radius = 5, color = \"red\", fillOpacity = 0.6,\n    group = \"Original\"\n  ) %&gt;%\n  addCircleMarkers(\n    data = your_masked,\n    radius = 5, color = \"blue\", fillOpacity = 0.6,\n    group = paste0(\"Masked (\", my_threshold, \"m)\")\n  ) %&gt;%\n  addLayersControl(\n    overlayGroups = c(\"Original\", paste0(\"Masked (\", my_threshold, \"m)\")),\n    options = layersControlOptions(collapsed = FALSE)\n  )\n\n\nQuestion: At what zoom level do the original and masked points become visually distinguishable? Is this consistent with your chosen threshold?\n\n\n\nStep 4: Assess Impact on Your Analysis\nChoose one spatial analysis relevant to your dataset (e.g., counts by administrative unit, distance to facilities, cluster detection) and assess how geomasking affects the results.\nQuestion: Describe the analysis you performed and how geomasking changed the results. Was the impact acceptable given your analytical goals? If the impact was too large, would you consider reducing the threshold, or would you accept reduced precision to maintain privacy protection?\n\n\n\nStep 5: Reflection on the Privacy-Utility Trade-off\nQuestion: Reflect on the overall geomasking process for your dataset. Address the following:\n\nDid your chosen threshold provide adequate privacy protection for the sensitivity of your data? How do you know?\nDid geomasking preserve the spatial patterns needed for your analytical purposes? What patterns were preserved, and what precision was lost?\nIf you were preparing this dataset for public release, would you use the same threshold? Why or why not?\nWhat additional privacy protections (temporal aggregation, attribute suppression, access controls) might you combine with geomasking?\n\nNOTE: There is no single “correct” threshold—the goal is to demonstrate thoughtful consideration of the privacy-utility trade-off in your specific context. Students who choose different thresholds for different types of data are demonstrating appropriate critical thinking."
  }
]